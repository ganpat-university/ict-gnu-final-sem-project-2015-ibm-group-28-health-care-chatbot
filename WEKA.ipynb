{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements \n",
    "    ### Visual C++ 14 v \n",
    "    ### javabridge \n",
    "    ### Pip install python-weka-wrapper3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\javabridge\\\\jars\\\\rhino-1.7R4.jar', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\javabridge\\\\jars\\\\runnablequeue.jar', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\javabridge\\\\jars\\\\cpython.jar', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\python-weka-wrapper.jar', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    }
   ],
   "source": [
    "import weka.core.jvm as jvm\n",
    "jvm.start()\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Classifier\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "\n",
    "data_dir = \"D:\\\\Rahul\\\\HealthCare ChatBot\\\\healthcare-dataset-stroke-data\\\\\"\n",
    "data = loader.load_file(\"Smote.arff\")\n",
    "data.class_is_last()\n",
    "\n",
    "#print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading saved model or using weka models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cls = Classifier(classname=\"weka.classifiers.meta.AdaBoostM1\",options=[\"-W\", \"weka.classifiers.trees.REPTree\"])\n",
    "#print(cls.to_help())\n",
    "#cls.build_classifier(data)\n",
    "\n",
    "import weka.core.serialization as serialization\n",
    "\n",
    "objects = serialization.read_all(\"J48.model\")\n",
    "csr = Classifier(jobject=objects[0])\n",
    "#print(classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test Data :  96.36873222724576\n",
      "Confusion Matrix  :  \n",
      "Correctly Classified Instances       47106               96.3687 %\n",
      "Incorrectly Classified Instances      1775                3.6313 %\n",
      "Kappa statistic                          0.8292\n",
      "Mean absolute error                      0.0358\n",
      "Root mean squared error                  0.1822\n",
      "Relative absolute error                 16.0411 %\n",
      "Root relative squared error             54.5242 %\n",
      "Total Number of Instances            48881     \n",
      "\n",
      "=== Detailed Accuracy By Class ===\n",
      "\n",
      "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
      "                 0.987    0.198    0.971      0.987    0.979      0.831    0.957     0.990     no\n",
      "                 0.802    0.013    0.904      0.802    0.850      0.831    0.958     0.901     yes\n",
      "Weighted Avg.    0.964    0.174    0.963      0.964    0.963      0.831    0.957     0.979     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#weka.classifiers.meta.AdaBoostM1 -P 100 -S 1 -I 10 -W weka.classifiers.trees.REPTree -- -M 2 -V 0.001 -N 3 -S 1 -L -1 -I 0.0\n",
    "#print(cls)\n",
    "from weka.classifiers import PredictionOutput\n",
    "from weka.classifiers import Evaluation\n",
    "from weka.core.classes import Random\n",
    "pout = PredictionOutput(classname=\"weka.classifiers.evaluation.output.prediction.PlainText\")\n",
    "\n",
    "# data to predit\n",
    "#data1 = loader.load_file(data_dir + \"Smote11.arff\") #or test 11\n",
    "#data1.class_is_last()\n",
    "\n",
    "# Model Evaluation\n",
    "evl = Evaluation(data)\n",
    "evl.crossvalidate_model(csr, data,2,Random(1))\n",
    "#evl.test_model(csr,data1,pout)\n",
    "\n",
    "print(\"Accuracy on test Data : \" ,evl.percent_correct)\n",
    "print(\"Confusion Matrix  : \"  ,evl.summary())\n",
    "print(evl.class_details())\n",
    "\n",
    "#print(evl.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Instance      Actual     Predicted\n",
      "        1        1:?       1:no       1 \n",
      "        2        1:?       1:no       1 \n",
      "        3        1:?      2:Yes       1 \n",
      "        4        1:?      2:Yes       1 \n",
      "        5        1:?      2:Yes       1 \n",
      "        6        1:?       1:no       1 \n",
      "        7        1:?       1:no       1 \n",
      "        8        1:?       1:no       1 \n",
      "        9        1:?       1:no       1 \n",
      "       10        1:?       1:no       1 \n",
      "       11        1:?       1:no       1 \n",
      "       12        1:?       1:no       1 \n",
      "       13        1:?       1:no       1 \n",
      "       14        1:?       1:no       1 \n",
      "       15        1:?       1:no       1 \n",
      "       16        1:?       1:no       1 \n",
      "       17        1:?       1:no       1 \n",
      "       18        1:?       1:no       1 \n",
      "       19        1:?       1:no       1 \n",
      "       20        1:?      2:Yes       1 \n",
      "       21        1:?      2:Yes       1 \n",
      "       22        1:?      2:Yes       1 \n",
      "       23        1:?       1:no       1 \n",
      "       24        1:?       1:no       1 \n",
      "       25        1:?       1:no       1 \n",
      "       26        1:?       1:no       1 \n",
      "       27        1:?       1:no       1 \n",
      "       28        1:?       1:no       1 \n",
      "       29        1:?       1:no       1 \n",
      "       30        1:?       1:no       1 \n",
      "       31        1:?       1:no       1 \n",
      "       32        1:?       1:no       1 \n",
      "       33        1:?       1:no       1 \n",
      "       34        1:?       1:no       1 \n",
      "       35        1:?       1:no       1 \n",
      "       36        1:?       1:no       1 \n",
      "       37        1:?      2:Yes       1 \n",
      "       38        1:?      2:Yes       1 \n",
      "       39        1:?      2:Yes       1 \n",
      "       40        1:?       1:no       1 \n",
      "       41        1:?       1:no       1 \n",
      "       42        1:?       1:no       1 \n",
      "       43        1:?       1:no       1 \n",
      "       44        1:?       1:no       1 \n",
      "       45        1:?       1:no       1 \n",
      "       46        1:?       1:no       1 \n",
      "       47        1:?       1:no       1 \n",
      "       48        1:?       1:no       1 \n",
      "       49        1:?       1:no       1 \n",
      "       50        1:?       1:no       1 \n",
      "       51        1:?       1:no       1 \n",
      "       52        1:?       1:no       1 \n",
      "       53        1:?       1:no       1 \n",
      "       54        1:?      2:Yes       1 \n",
      "       55        1:?      2:Yes       1 \n",
      "       56        1:?      2:Yes       1 \n",
      "       57        1:?       1:no       1 \n",
      "       58        1:?       1:no       1 \n",
      "       59        1:?       1:no       1 \n",
      "       60        1:?       1:no       1 \n",
      "       61        1:?       1:no       1 \n",
      "       62        1:?       1:no       1 \n",
      "       63        1:?       1:no       1 \n",
      "       64        1:?       1:no       1 \n",
      "       65        1:?       1:no       1 \n",
      "       66        1:?       1:no       1 \n",
      "       67        1:?       1:no       1 \n",
      "       68        1:?       1:no       1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = loader.load_file(\"test.arff\") #or test 11\n",
    "data1.class_is_last()\n",
    "ev2 = Evaluation(data1)\n",
    "ev2.test_model(csr,data1,pout)\n",
    "\n",
    "print(\"     Instance\",\"     Actual\",\"    Predicted\")\n",
    "print(pout.buffer_content())\n",
    "\n",
    "#import weka.plot.classifiers as plcls  # NB: matplotlib is required\n",
    "#plcls.plot_classifier_errors(evl.predictions, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jvm.stop() #to stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
